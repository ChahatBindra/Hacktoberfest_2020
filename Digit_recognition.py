# -*- coding: utf-8 -*-
"""DL_lab_7_E18CSE037.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gCIQn7R98_25-yEDm-B5sNzo--D_7ykP
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.datasets import mnist
from keras.models import Sequential,model_from_json
from keras.layers import Dense
from keras.layers import Conv2D
from keras.layers import MaxPool2D
from keras.layers import Flatten
from keras.optimizers import RMSprop
import pylab as plt
from keras.utils import np_utils

(X_train,y_train) , (X_test,y_test) = mnist.load_data()

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

X_train = X_train.reshape(60000, 28,28,1)
X_test = X_test.reshape(10000, 28,28,1)   

X_train = X_train.astype('float32')   
X_test = X_test.astype('float32')

X_train /= 255                       
X_test /= 255

print("Training matrix shape", X_train.shape)
print("Testing matrix shape", X_test.shape)

nb_classes = 10 # number of unique digits

Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

print(Y_train.shape)
print(Y_test.shape)

Y_test

"""Base Model"""

model = Sequential()
model.add(Conv2D(24,kernel_size=5,padding='same',strides = (1,1),activation='relu',input_shape=(28,28,1)))
model.add(MaxPool2D())
model.add(Conv2D(48,kernel_size=5,padding='same',strides = (1,1),activation='relu'))
model.add(MaxPool2D())
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.compile(optimizer="adam", loss="categorical_crossentropy")
model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train, Y_train,batch_size=128, epochs=5,verbose=1)

score = model.evaluate(X_test, Y_test)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

prediction = model.predict(X_test[420:421])
prediction = prediction[0]
print('Prediction\n',prediction)
print(np.argmax(prediction))
plt.imshow(X_test[420:421].reshape(28,28))

"""Number of filters: Run CNN with 1 convolution hidden layer (32 filters of 3*3), flatten
layer and output layer, (with any activation function and any optimizer) for 5 epochs.
Change number of filters as 4, 32, 128, 512, 2056. What is the training and testing
accuracies? Print the number of parameters of the model and training time for each of
these configurations.

32 filters of 4*4, flatten layer and output layer,
"""

def define_model1():
  model=Sequential()
  model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))
  model.add(MaxPool2D((2,2)))
  model.add(Flatten())

  model.add(Dense(100,activation='relu'))
  model.add(Dense(10,activation='softmax'))
  model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
  return model

model=define_model1()
history=model.fit(X_train,Y_train,epochs=10,batch_size=32,validation_data=(X_test,Y_test),verbose=0)
_,acc=model.evaluate(X_test,Y_test,verbose=0)
print('%.3f'%(acc*100.0))

model.weights

model.summary()

scores,histories=list(),list()
scores.append(acc)
histories.append(history)

import matplotlib
import matplotlib.pyplot as plt
from matplotlib import pyplot

def summarize_diagnostics(histories):
  for i in range(len(histories)):
    pyplot.subplot(2,1,1)
    pyplot.title('CROSS ENTROPY LOSS')
    pyplot.plot(histories[i].history['loss'],color='blue',label='train')
    pyplot.plot(histories[i].history['val_loss'],color='orange',label='test')
    pyplot.subplot(2,1,2)
    pyplot.title('CLASSIFICATION ACCURACY')
    pyplot.plot(histories[i].history['accuracy'],color='blue',label='train')
    pyplot.plot(histories[i].history['val_accuracy'],color='orange',label='test')
  pyplot.show()

summarize_diagnostics(histories)

